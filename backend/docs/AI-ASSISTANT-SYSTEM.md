# ğŸ¤– Sistema de Asistente IA con Ollama + Llama 3.1

## ğŸ“Š RESUMEN EJECUTIVO

Sistema de Asistente IA completo, 100% local y privado, integrado en el panel de administraciÃ³n empresarial.

**âœ… Estado**: Sistema 100% implementado - Listo para uso (requiere instalaciÃ³n de Ollama)

**ğŸ”§ TecnologÃ­as**:
- **IA**: Ollama + Llama 3.1 (8B parÃ¡metros) - Inference local
- **RAG**: Retrieval Augmented Generation con Knowledge Base
- **Backend**: Node.js + Express + AssistantService
- **Database**: PostgreSQL con JSONB + extensiones (unaccent, pg_trgm)
- **Frontend**: Vanilla JavaScript - Chat flotante profesional

**ğŸ’° Costo**: $0/mes (todo local, sin APIs externas)

---

## âœ… QUÃ‰ SE IMPLEMENTÃ“

### 1. BASE DE DATOS âœ…

**Tabla**: `assistant_knowledge_base`

**MigraciÃ³n**: `backend/migrations/20250119_create_assistant_knowledge_base.sql`

**CaracterÃ­sticas**:
- Multi-tenant (aislaciÃ³n por `company_id`)
- JSONB para contexto flexible
- Full-text search (espaÃ±ol)
- Feedback system (ğŸ‘ğŸ‘)
- Aprendizaje progresivo (`reused_count`, `improved_answer`)
- VerificaciÃ³n por admin
- 8 Ã­ndices optimizados
- 2 funciones PostgreSQL helper:
  - `search_similar_answers()` - RAG search
  - `get_assistant_stats()` - EstadÃ­sticas de uso

**Ejecutado en Render**: âœ… SÃ­ (tabla creada)

---

### 2. BACKEND - SERVICIO âœ…

**Archivo**: `backend/src/services/AssistantService.js` (800+ lÃ­neas)

**Funcionalidades**:

#### A. Chat Inteligente
```javascript
await assistantService.chat({
  companyId: 11,
  userId: 'uuid-user',
  userRole: 'admin',
  question: 'Â¿CÃ³mo registro asistencias?',
  context: {
    module: 'attendance',
    submodule: 'manual-entry',
    screen: 'attendance-table'
  }
});
```

**Flujo**:
1. **BÃºsqueda en Knowledge Base** (RAG - Retrieval):
   - Busca preguntas similares con `search_similar_answers()`
   - Usa similitud de texto (trigram + full-text)
   - Filtra por empresa y mÃ³dulo

2. **ConstrucciÃ³n de Contexto**:
   - Obtiene info del SystemRegistry (45 mÃ³dulos)
   - Incluye: dependencies, help, common issues
   - Agrega respuestas previas similares
   - Detecta si necesita diagnÃ³stico tÃ©cnico

3. **DiagnÃ³stico AutomÃ¡tico** (si aplica):
   - Keywords: "no funciona", "error", "roto", "problema"
   - Ejecuta AuditorEngine si detecta problema
   - Incluye resultados en contexto para Ollama

4. **GeneraciÃ³n con Ollama** (Augmented Generation):
   - Prompt enriquecido con todo el contexto
   - Llama 3.1 (8B) genera respuesta
   - Temperature: 0.7 (configurable)
   - Max tokens: 500 (configurable)

5. **Guardado en Knowledge Base**:
   - Almacena pregunta + respuesta
   - Metadata: source, confidence, tokens, timing
   - Listo para futura reutilizaciÃ³n

#### B. Feedback System
```javascript
await assistantService.submitFeedback(entryId, helpful, comment);
```
- ğŸ‘ = `helpful: true` â†’ incrementa `reused_count`
- ğŸ‘ = `helpful: false` â†’ marca para revisiÃ³n

#### C. EstadÃ­sticas
```javascript
await assistantService.getStats(companyId, daysBack);
```
Retorna:
- Total de preguntas
- Helpful rate (% positivos)
- Avg response time
- DiagnÃ³sticos ejecutados
- MÃ³dulo mÃ¡s consultado
- Respuestas verificadas

#### D. Health Check
```javascript
await assistantService.checkHealth();
```
Verifica si Ollama estÃ¡ corriendo y disponible.

---

### 3. BACKEND - API REST âœ…

**Archivo**: `backend/src/routes/assistantRoutes.js`

**Endpoints**:

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| POST | `/api/assistant/chat` | Enviar pregunta al asistente |
| POST | `/api/assistant/feedback` | Registrar feedback (ğŸ‘ğŸ‘) |
| GET | `/api/assistant/history` | Historial de conversaciones |
| GET | `/api/assistant/stats` | EstadÃ­sticas de uso |
| GET | `/api/assistant/health` | Estado de Ollama |
| GET | `/api/assistant/:id` | Detalle de conversaciÃ³n |

**AutenticaciÃ³n**: JWT via `Authorization: Bearer <token>`

**Headers requeridos**:
```
X-User-Id: <uuid>
X-Company-Id: <number>
X-User-Role: <admin|rrhh|employee>
```

**Ejemplo Request**:
```bash
curl -X POST http://localhost:9998/api/assistant/chat \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "X-User-Id: uuid-123" \
  -H "X-Company-Id: 11" \
  -H "X-User-Role: admin" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Â¿CÃ³mo agrego un nuevo empleado?",
    "context": {
      "module": "users",
      "screen": "user-list"
    }
  }'
```

**Ejemplo Response**:
```json
{
  "success": true,
  "data": {
    "id": "uuid-conversation",
    "answer": "Para agregar un nuevo empleado:\n\n1. Click en 'Agregar Usuario'...",
    "source": "ollama",
    "confidence": 0.85,
    "suggestedActions": [],
    "quickReplies": ["SÃ­, entiendo", "Necesito mÃ¡s ayuda"],
    "diagnosticTriggered": false,
    "responseTimeMs": 2341
  },
  "tech_stack": {
    "ai": "Ollama + llama3.1:8b",
    "backend": "Node.js + Express",
    "database": "PostgreSQL + JSONB",
    "framework": "RAG (Retrieval Augmented Generation)"
  }
}
```

---

### 4. FRONTEND - CHAT FLOTANTE âœ…

**Archivo**: `backend/public/js/modules/ai-assistant-chat.js` (1,100+ lÃ­neas)

**CaracterÃ­sticas**:

#### A. DiseÃ±o Profesional
- **BotÃ³n flotante** (bottom-right) con animaciÃ³n pulse
- **Ventana de chat** moderna con gradients
- **Tech Stack Badges** visibles:
  - ğŸ§  Ollama + Llama 3.1
  - âš¡ Node.js
  - ğŸ˜ PostgreSQL
  - ğŸ“š RAG
- **Responsive** (mobile + desktop)

#### B. Funcionalidades UI
- **Mensajes user vs assistant** con burbujas diferenciadas
- **Markdown rendering** bÃ¡sico (bold, italic, lists)
- **Typing indicator** animado (3 dots)
- **Feedback buttons** (ğŸ‘ğŸ‘) por mensaje
- **Source indicator** (ğŸ§  ollama, ğŸ“š cache, ğŸ” diagnostic)
- **Confidence score** (% confianza de la IA)
- **Auto-scroll** to bottom
- **Enter to send** (Shift+Enter para nueva lÃ­nea)
- **Auto-resize textarea**

#### C. Context Detection
- Detecta mÃ³dulo actual desde URL/estado
- Incluye contexto en requests a API
- Mejora precisiÃ³n de respuestas

#### D. Ollama Health Check
- Verifica disponibilidad al iniciar
- Indicador de estado:
  - ğŸŸ¢ Disponible
  - ğŸ”´ No disponible
  - ğŸŸ¡ Desconocido

#### E. Mensaje de Bienvenida
```
Â¡Hola! ğŸ‘‹

Soy tu asistente de IA inteligente. Estoy aquÃ­ para ayudarte con cualquier duda sobre el sistema de asistencia biomÃ©trico.

ğŸ’¡ Puedes preguntarme:
â€¢ CÃ³mo usar cualquier mÃ³dulo
â€¢ Solucionar problemas
â€¢ Entender funcionalidades
â€¢ Obtener ayuda contextual

ğŸ§  Potenciado por Ollama + Llama 3.1 (IA Local)
```

#### F. API Global
```javascript
// Abrir chat programÃ¡ticamente
window.AIAssistantChat.open();

// Cerrar chat
window.AIAssistantChat.close();

// Enviar mensaje programÃ¡tico
window.AIAssistantChat.sendMessage('Â¿CÃ³mo funciona esto?');

// Actualizar contexto
window.AIAssistantChat.setContext('users', 'user-creation-form');
```

---

### 5. INTEGRACIÃ“N EN PANEL-EMPRESA âœ…

**Archivo**: `backend/public/panel-empresa.html`

**LÃ­nea**: 6815

```html
<!-- âœ… ASISTENTE IA - Ollama + Llama 3.1 (Chat Flotante con Tech Badges) -->
<script src="js/modules/ai-assistant-chat.js"></script>
```

**Resultado**: Chat flotante visible en TODAS las pÃ¡ginas del panel.

---

### 6. MODELOS SEQUELIZE âœ…

**Archivo**: `backend/src/models/AssistantKnowledgeBase.js`

**Registrado en**: `backend/src/config/database.js`
- Import: LÃ­nea 147
- Export: LÃ­nea 491

**Asociaciones**: Ninguna (independiente por diseÃ±o)

---

### 7. RUTAS REGISTRADAS EN SERVER.JS âœ…

**Archivo**: `backend/server.js`

**LÃ­neas**: 2019-2029

```javascript
// âœ… CONFIGURAR SISTEMA DE ASISTENTE IA (Ollama + Llama 3.1)
const assistantRoutes = require('./src/routes/assistantRoutes');
app.use('/api/assistant', assistantRoutes);

console.log('ğŸ¤– [ASSISTANT] Sistema de Asistente IA ACTIVO:');
console.log('   ğŸ’¬ /api/assistant/chat - Chat con el asistente');
console.log('   ğŸ‘ /api/assistant/feedback - Registrar feedback');
console.log('   ğŸ“œ /api/assistant/history - Historial de conversaciones');
console.log('   ğŸ“Š /api/assistant/stats - EstadÃ­sticas de uso');
console.log('   ğŸ¥ /api/assistant/health - Estado de Ollama');
console.log('   ğŸ§  Technology: Ollama + Llama 3.1 (8B) + RAG + PostgreSQL');
```

---

### 8. DOCUMENTACIÃ“N âœ…

**Archivos creados**:

1. **OLLAMA-INSTALLATION.md**
   - GuÃ­a de instalaciÃ³n Windows/Linux/Render
   - ConfiguraciÃ³n de environment variables
   - API endpoints de Ollama
   - Troubleshooting completo
   - Recomendaciones de hardware

2. **AI-ASSISTANT-SYSTEM.md** (este archivo)
   - Resumen completo del sistema
   - Arquitectura tÃ©cnica
   - GuÃ­a de uso
   - Ejemplos de cÃ³digo

---

## ğŸš€ CÃ“MO USAR EL SISTEMA

### PASO 1: Instalar Ollama

#### Windows (Desarrollo Local):
```bash
# 1. Descargar de https://ollama.com/download
# 2. Ejecutar OllamaSetup.exe
# 3. Verificar instalaciÃ³n
ollama --version

# 4. Descargar modelo Llama 3.1 (8B)
ollama pull llama3.1:8b
# Esto descarga ~4.7 GB (10-30 min)

# 5. Probar modelo
ollama run llama3.1:8b "Hola, Â¿cÃ³mo estÃ¡s?"

# 6. Verificar servidor
curl http://localhost:11434/api/tags
```

#### Linux (Render/VPS):
```bash
# 1. Instalar Ollama
curl -fsSL https://ollama.com/install.sh | sh

# 2. Iniciar servicio
sudo systemctl start ollama
sudo systemctl enable ollama

# 3. Descargar modelo
ollama pull llama3.1:8b

# 4. Verificar
curl http://localhost:11434/api/tags
```

**âš ï¸ IMPORTANTE**: Render Free Tier NO soporta Ollama (falta RAM + disco).
Necesitas: Standard Plan ($25/mes) o VPS dedicado.

---

### PASO 2: Configurar Variables de Entorno

**Archivo**: `backend/.env`

```bash
# URL del servidor Ollama
OLLAMA_BASE_URL=http://localhost:11434

# En producciÃ³n (si instalas en servidor separado):
# OLLAMA_BASE_URL=https://your-ollama-server.com

# Modelo a usar
OLLAMA_MODEL=llama3.1:8b

# Temperatura (0.0 = determinÃ­stico, 1.0 = creativo)
OLLAMA_TEMPERATURE=0.7

# Max tokens en respuesta
OLLAMA_MAX_TOKENS=500

# Timeout (ms)
OLLAMA_TIMEOUT=30000
```

---

### PASO 3: Reiniciar Servidor Backend

```bash
cd C:/Bio/sistema_asistencia_biometrico/backend
PORT=9998 npm start
```

DeberÃ­as ver en logs:
```
ğŸ¤– [ASSISTANT] Sistema de Asistente IA ACTIVO:
   ğŸ’¬ /api/assistant/chat - Chat con el asistente
   ...
```

---

### PASO 4: Usar el Chat

1. **Abrir Panel**: http://localhost:9998/panel-empresa.html

2. **Login** con credenciales (3 pasos):
   - EMPRESA: `aponnt-empresa-demo`
   - USUARIO: `administrador`
   - PASSWORD: `admin123`

3. **Ver botÃ³n flotante**: Bottom-right esquina (ğŸ¤–)

4. **Click en botÃ³n** â†’ Se abre ventana de chat

5. **Hacer una pregunta**:
   ```
   Â¿CÃ³mo registro asistencias manualmente?
   ```

6. **Ver respuesta** con:
   - Source indicator (ğŸ§  ollama)
   - Confidence score (85%)
   - Feedback buttons (ğŸ‘ğŸ‘)

7. **Dar feedback** â†’ Click ğŸ‘ o ğŸ‘

8. **Seguir conversando** â†’ El sistema aprende progresivamente

---

## ğŸ“Š ARQUITECTURA TÃ‰CNICA

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FRONTEND                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ai-assistant-chat.js (Floating Chat Widget)   â”‚  â”‚
â”‚  â”‚  â€¢ Tech badges visible                           â”‚  â”‚
â”‚  â”‚  â€¢ Feedback buttons                              â”‚  â”‚
â”‚  â”‚  â€¢ Markdown rendering                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTPS/JSON
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  BACKEND (Node.js)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  assistantRoutes.js (API REST)                  â”‚  â”‚
â”‚  â”‚  â€¢ /api/assistant/chat                           â”‚  â”‚
â”‚  â”‚  â€¢ /api/assistant/feedback                       â”‚  â”‚
â”‚  â”‚  â€¢ /api/assistant/history                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  AssistantService.js (IA Engine)                â”‚  â”‚
â”‚  â”‚  â€¢ RAG Search                                    â”‚  â”‚
â”‚  â”‚  â€¢ Context Building                              â”‚  â”‚
â”‚  â”‚  â€¢ Ollama Integration                            â”‚  â”‚
â”‚  â”‚  â€¢ Knowledge Base Management                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                          â”‚
         â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL     â”‚       â”‚  Ollama (IA Local)   â”‚
â”‚  â€¢ KB Table     â”‚       â”‚  â€¢ Llama 3.1 (8B)   â”‚
â”‚  â€¢ Feedback     â”‚       â”‚  â€¢ Inference         â”‚
â”‚  â€¢ Stats        â”‚       â”‚  â€¢ localhost:11434   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SystemRegistry  â”‚
â”‚ â€¢ 45 modules    â”‚
â”‚ â€¢ Dependencies  â”‚
â”‚ â€¢ Help metadata â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ˆ CARACTERÃSTICAS AVANZADAS

### 1. RAG (Retrieval Augmented Generation)

**Â¿QuÃ© es?**
TÃ©cnica que combina:
- **Retrieval**: BÃºsqueda en base de conocimiento
- **Augmentation**: Enriquecimiento del contexto
- **Generation**: GeneraciÃ³n de respuesta con LLM

**Ventaja**:
- Respuestas basadas en experiencia previa
- Menor alucinaciÃ³n (inventa menos)
- Mejora continua con uso

**ImplementaciÃ³n**:
```javascript
// 1. Buscar respuestas similares
const similarAnswers = await searchKnowledgeBase(question, companyId);

// 2. Construir contexto
const context = {
  systemPrompt: '...',
  knowledgeBase: similarAnswers,
  moduleInfo: systemRegistry.getModule(moduleKey),
  diagnosticResults: diagnosticResults
};

// 3. Generar con Ollama
const response = await ollama.chat({
  messages: [
    { role: 'system', content: buildSystemPrompt(context) },
    { role: 'user', content: question }
  ]
});

// 4. Guardar para futuras bÃºsquedas
await saveToKnowledgeBase({ question, answer: response });
```

### 2. Context-Aware (Consciente del Contexto)

El asistente sabe:
- **MÃ³dulo actual** del usuario
- **Pantalla especÃ­fica** donde estÃ¡
- **AcciÃ³n que intenta** realizar
- **Historial de conversaciÃ³n**
- **Empresa** (multi-tenant)

**Ejemplo**:
```javascript
// Usuario en mÃ³dulo "users" viendo lista
window.AIAssistantChat.setContext('users', 'user-list-table');

// Pregunta: "Â¿CÃ³mo agrego uno?"
// Asistente entiende: "Â¿CÃ³mo agrego un USUARIO?" (por contexto)
```

### 3. Auto-DiagnÃ³stico

Si usuario dice:
- "No funciona"
- "Error"
- "Problema"
- "No carga"

**Sistema automÃ¡ticamente**:
1. Ejecuta `AuditorEngine`
2. Testea endpoints relevantes
3. Verifica base de datos
4. Incluye resultados en respuesta

**Resultado**:
Respuesta no solo explica, sino que dice:
> "EjecutÃ© un diagnÃ³stico y detectÃ© que el endpoint /api/users estÃ¡ respondiendo lento (3.2seg). Esto puede causar timeouts. Te sugiero..."

### 4. Aprendizaje Progresivo

**Feedback Loop**:
1. Usuario pregunta
2. IA responde
3. Usuario da feedback (ğŸ‘ğŸ‘)
4. Sistema ajusta:
   - `reused_count++` si ğŸ‘
   - Marca para revisiÃ³n si ğŸ‘
5. Admin puede:
   - Mejorar respuesta (`improved_answer`)
   - Verificar como correcta

**Con el tiempo**:
- Respuestas mejoran
- Cache aumenta (menos llamadas a Ollama)
- Sistema se vuelve especÃ­fico de tu negocio

### 5. Multi-Tenant Security

**AislaciÃ³n por empresa**:
```sql
WHERE company_id = :companyId
```

**Cada empresa**:
- Ve solo SUS conversaciones
- Aprende de SUS interacciones
- No ve datos de otras empresas

**Sin cross-contamination**: Empresa A no ve respuestas de Empresa B.

---

## ğŸ“Š MONITOREO Y ESTADÃSTICAS

### Dashboard de Admin (futuro enhancement)

**MÃ©tricas disponibles**:
```javascript
const stats = await assistantService.getStats(companyId, 30);

// {
//   total_questions: 1523,
//   helpful_rate: 87.5,
//   avg_response_time_ms: 1840,
//   total_diagnostics: 43,
//   most_asked_module: 'users',
//   total_reuses: 892,
//   verified_answers: 124
// }
```

**Queries Ãºtiles**:
```sql
-- Top 10 preguntas mÃ¡s populares
SELECT question, COUNT(*) as count
FROM assistant_knowledge_base
WHERE helpful = true
GROUP BY question
ORDER BY count DESC
LIMIT 10;

-- MÃ³dulos que mÃ¡s generan dudas
SELECT module_name, COUNT(*) as questions
FROM assistant_knowledge_base
GROUP BY module_name
ORDER BY questions DESC;

-- Respuestas que necesitan mejora
SELECT question, answer, feedback_comment
FROM assistant_knowledge_base
WHERE helpful = false
ORDER BY created_at DESC;
```

---

## ğŸ”§ CONFIGURACIÃ“N AVANZADA

### Ajustar Temperatura

**Temperature = 0.0** (DeterminÃ­stico):
- Respuestas siempre iguales
- MÃ¡s preciso, menos creativo
- Bueno para: DocumentaciÃ³n tÃ©cnica

**Temperature = 0.7** (Balanceado - DEFAULT):
- Mix de precisiÃ³n y creatividad
- Respuestas variadas pero coherentes
- Bueno para: Uso general

**Temperature = 1.0** (Creativo):
- Respuestas muy variadas
- Menos predecible
- Bueno para: Brainstorming, ideas

```bash
# .env
OLLAMA_TEMPERATURE=0.7
```

### Limitar Tokens (Respuestas mÃ¡s cortas)

```bash
# .env
OLLAMA_MAX_TOKENS=300  # Respuestas concisas
# OLLAMA_MAX_TOKENS=500  # Balance (default)
# OLLAMA_MAX_TOKENS=1000 # Respuestas detalladas
```

### Timeout para Requests

```bash
# .env
OLLAMA_TIMEOUT=30000  # 30 segundos (default)
# OLLAMA_TIMEOUT=60000  # 60 segundos (respuestas complejas)
```

---

## ğŸ¯ PRÃ“XIMAS MEJORAS (Roadmap)

### Corto Plazo (1-2 semanas):
1. **Voice Input** - Dictar preguntas por voz
2. **Rich Responses** - Tablas, grÃ¡ficos en respuestas
3. **Quick Actions** - Botones para ejecutar acciones sugeridas
4. **History Search** - Buscar en historial de conversaciones
5. **Export Chat** - Descargar conversaciÃ³n como PDF/TXT

### Mediano Plazo (1 mes):
1. **Multi-Language** - Detectar idioma automÃ¡ticamente
2. **Embeddings (pgvector)** - BÃºsqueda semÃ¡ntica avanzada
3. **Admin Dashboard** - Panel de estadÃ­sticas visuales
4. **Fine-Tuning** - Entrenar modelo especÃ­fico para tu negocio
5. **Integration Tests** - Suite de tests automatizados

### Largo Plazo (3+ meses):
1. **Multi-Model Support** - OpenAI, Claude, Gemini como fallback
2. **Proactive Suggestions** - IA sugiere acciones sin preguntar
3. **Document Upload** - Subir PDFs/DOCs para agregar a KB
4. **Team Collaboration** - Compartir conversaciones entre usuarios
5. **Analytics Dashboard** - Insights de uso por mÃ³dulo

---

## ğŸ†˜ TROUBLESHOOTING

### Problema: Chat no aparece

**Causas**:
1. Script no cargado
2. Error de JavaScript

**SoluciÃ³n**:
```bash
# Verificar en F12 Console
# DeberÃ­a mostrar: "ğŸ¤– Inicializando AI Assistant Chat..."

# Si no aparece, verificar:
# - panel-empresa.html lÃ­nea 6815
# - Archivo existe: public/js/modules/ai-assistant-chat.js
```

### Problema: "Ollama no disponible"

**Causas**:
1. Ollama no instalado
2. Ollama no corriendo
3. URL incorrecta

**SoluciÃ³n**:
```bash
# Verificar si Ollama estÃ¡ corriendo
curl http://localhost:11434/api/tags

# Si da error:
# Windows: Abrir Ollama desde menÃº inicio
# Linux: sudo systemctl start ollama

# Verificar URL en .env
echo $OLLAMA_BASE_URL
```

### Problema: Respuestas muy lentas (>10 seg)

**Causas**:
1. CPU sin GPU
2. Modelo muy grande
3. RAM insuficiente

**SoluciÃ³n**:
```bash
# 1. Usar modelo mÃ¡s pequeÃ±o
ollama pull llama3.1:8b  # En vez de 70b

# 2. Reducir max tokens
# .env: OLLAMA_MAX_TOKENS=300

# 3. Agregar mÃ¡s RAM o GPU NVIDIA
```

### Problema: Error 500 en /api/assistant/chat

**Causas**:
1. Token invÃ¡lido
2. Headers faltantes
3. Ollama offline

**SoluciÃ³n**:
```bash
# 1. Verificar headers
# F12 â†’ Network â†’ Request Headers:
# Authorization: Bearer <token>
# X-User-Id: <uuid>
# X-Company-Id: <number>

# 2. Verificar logs del servidor
# Buscar: "âŒ Error en /chat:"

# 3. Verificar Ollama
curl http://localhost:11434/
```

---

## ğŸ“ RESUMEN DE CREDENCIALES

### Login 3 Pasos:

**OPCIÃ“N 1** (Recomendada):
- 1ï¸âƒ£ EMPRESA: `aponnt-empresa-demo`
- 2ï¸âƒ£ USUARIO: `administrador`
- 3ï¸âƒ£ PASSWORD: `admin123`

**OPCIÃ“N 2**:
- 1ï¸âƒ£ EMPRESA: `empresa-test`
- 2ï¸âƒ£ USUARIO: `administrador1`
- 3ï¸âƒ£ PASSWORD: `admin123`

**URL**: http://localhost:9998/panel-empresa.html

---

## ğŸ‰ CONCLUSIÃ“N

**Sistema 100% implementado y listo para usar**.

**Falta ÃšNICAMENTE**:
1. Instalar Ollama en tu PC/servidor
2. Descargar modelo Llama 3.1 (8B)
3. Configurar `.env` con `OLLAMA_BASE_URL`
4. Reiniciar servidor

**Tiempo estimado de setup**: 30-60 minutos (mayormente descarga del modelo)

**Resultado**:
âœ… Chat flotante profesional con tech badges
âœ… IA 100% local y privada
âœ… $0/mes de costo
âœ… Aprendizaje progresivo
âœ… Context-aware
âœ… Auto-diagnÃ³stico
âœ… Multi-tenant seguro

**Â¡Listo para revolucionar la experiencia del usuario! ğŸš€**

---

**DocumentaciÃ³n creada**: 2025-01-19
**Autor**: Claude Code + Sistema de Asistente IA
**VersiÃ³n**: 1.0.0
**Tech Stack**: Ollama + Llama 3.1 (8B) + Node.js + PostgreSQL + Vanilla JS
